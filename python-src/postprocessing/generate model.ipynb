{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import linregress\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, concatenate, Conv2D\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shrink_array(array,size):\n",
    "    \n",
    "    ratio = float(len(array)) / float(size+1)\n",
    "    res = []\n",
    "    for i in range(size):\n",
    "        res.append(np.mean(array[math.floor(i*ratio):math.ceil((i+2.0)*ratio)], axis = 0))\n",
    "    return np.array(res)\n",
    "\n",
    "train_data = pd.DataFrame.from_csv(\"../../data/database/train_data.csv\")\n",
    "test_data = pd.DataFrame.from_csv(\"../../data/database/test_data.csv\")\n",
    "f_df = pd.DataFrame.from_csv(\"../../data/gesture_feature_df.csv\")\n",
    "\n",
    "feature_cols = ['global_acc3','acc_12_square']\n",
    "\n",
    "def get_feature_label(data, N):\n",
    "    groups = data.groupby(['TagName','tester_id'])\n",
    "    keys = groups.groups.keys()\n",
    "    y = []\n",
    "    X = []\n",
    "    for k in keys:\n",
    "        frame_feature = shrink_array(groups.get_group(k)[feature_cols].values, N)\n",
    "        X.append(frame_feature)\n",
    "        y.append(k[0])\n",
    "    return np.array(X),np.array(y)\n",
    "\n",
    "def get_feature_label_f(data, N):\n",
    "    groups = data.groupby(['TagName','tester_id'])\n",
    "    keys = groups.groups.keys()\n",
    "    y = []\n",
    "    X = []\n",
    "    f = []\n",
    "    for k in keys:\n",
    "        frame_feature = shrink_array(groups.get_group(k)[feature_cols].values, N)\n",
    "        X.append(frame_feature)\n",
    "        y.append(k[0])\n",
    "        f.append(f_df[(f_df.TagName == k[0]) & (f_df.tester_id == k[1])].d_change.values[0])\n",
    "    return np.array(X),np.array(y),np.array(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_06 = True\n",
    "if ensemble_06 is True:\n",
    "    rf_clf = joblib.load('../train/binary_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    N=14\n",
    "    X_train, y_train = get_feature_label(train_data, N)\n",
    "    x_test, y_test, f_test = get_feature_label_f(test_data, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    y = np.concatenate([y_train,y_test])\n",
    "    tag_list = []\n",
    "    for i in range(10):\n",
    "        tag_list.append(['Tag'+str(i),i])\n",
    "    for i in tag_list:\n",
    "        tag_str = i[0]\n",
    "        tag_int = i[1]\n",
    "        y[y==tag_str] = tag_int\n",
    "    y_categorical = to_categorical(y)\n",
    "    \n",
    "    y_train_cate = y_categorical[:len(y_train)]\n",
    "    y_test_cate = y_categorical[len(y_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Ageha/anaconda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_val1 = Input(shape=X_train.shape[1:])\n",
    "\n",
    "con1 = Conv1D(filters=30,kernel_size=5)(input_val1)\n",
    "max_pooling_1d_1 = MaxPooling1D(pool_size=2, strides=None, padding='valid')(con1)\n",
    "flat_1 = Flatten()(max_pooling_1d_1)\n",
    "layer2 = Dense(128, activation='relu')(flat_1)\n",
    "layer4 = Dense(32, activation='relu')(layer2)\n",
    "predictions = Dense(y_categorical.shape[-1], activation='softmax')(layer4)\n",
    "\n",
    "model = Model(inputs = input_val1, outputs=predictions)\n",
    "#         print(model.summary())\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_his = model.fit(X_train, y_train_cate, batch_size=32, epochs=32, verbose = 0,\n",
    "                      validation_data=(x_test, y_test_cate)\n",
    "                     )  # starts training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830, 14, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    graph_def = g.as_graph_def()\n",
    "    tf.train.write_graph(graph_def, './tmp/', 'model_not_freeze.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    save_path = saver.save(sess, \"./tmp/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"../train/tmp/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"./tmp/model_only_weight.h5\")\n",
    "model.save(\"./tmp/model_weight_structure.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = \"./SavedModelBuilder/\"\n",
    "\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "\n",
    "      builder.add_meta_graph_and_variables(sess,\n",
    "                                       [\"foo-tag\"])\n",
    "\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
