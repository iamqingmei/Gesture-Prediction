{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import linregress\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, concatenate, Conv2D\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_5models_from_disk():\n",
    "    models = []\n",
    "    for i in range(5):\n",
    "        json_file = open(\"./model\" + str(i) +\".json\", 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(\"temp\" + str(i) +\".hdf5\")\n",
    "#         print(\"Loaded model from disk\")\n",
    "\n",
    "        # evaluate loaded model on test data\n",
    "        loaded_model.compile(optimizer='rmsprop',\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "        models.append(loaded_model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shrink_array(array,size):\n",
    "    \n",
    "    ratio = float(len(array)) / float(size+1)\n",
    "    res = []\n",
    "    for i in range(size):\n",
    "        res.append(np.mean(array[math.floor(i*ratio):math.ceil((i+2.0)*ratio)], axis = 0))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_csv(\"../../data/global_acc_features_df.csv\")\n",
    "f_df = pd.DataFrame.from_csv(\"../../data/gesture_feature_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unix_timestamp', 'TagName', 'tester_id', 'v_1', 'v_2', 'v_3', 'd_1',\n",
       "       'd_2', 'd_3', 'global_acc1', 'global_acc2', 'global_acc3',\n",
       "       'v_12_square', 'acc_12_square', 'd_12_square'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = ['global_acc3','acc_12_square']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_feature_label(data, N):\n",
    "#     groups = data.groupby(['TagName','tester_id'])\n",
    "#     keys = groups.groups.keys()\n",
    "#     y = []\n",
    "#     X = []\n",
    "#     for k in keys:\n",
    "#         frame_feature = shrink_array(groups.get_group(k)[feature_cols].values, N)\n",
    "#         X.append(frame_feature)\n",
    "#         y.append(k[0])\n",
    "#     return np.array(X),np.array(y)\n",
    "\n",
    "# def get_feature_label_f(data, N):\n",
    "#     groups = data.groupby(['TagName','tester_id'])\n",
    "#     keys = groups.groups.keys()\n",
    "#     y = []\n",
    "#     X = []\n",
    "#     f = []\n",
    "#     for k in keys:\n",
    "#         frame_feature = shrink_array(groups.get_group(k)[feature_cols].values, N)\n",
    "#         X.append(frame_feature)\n",
    "#         y.append(k[0])\n",
    "#         f.append(f_df[(f_df.TagName == k[0]) & (f_df.tester_id == k[1])].d_change.values[0])\n",
    "#     return np.array(X),np.array(y),np.array(f)\n",
    "\n",
    "def get_feature_label(data_groups, keys, N):\n",
    "    y = []\n",
    "    X = []\n",
    "    f = []\n",
    "    for k in keys:\n",
    "        frame_feature = shrink_array(data_groups.get_group(k)[feature_cols].values, N)\n",
    "        X.append(frame_feature)\n",
    "        y.append(k[0])\n",
    "        f.append(f_df[(f_df.TagName == k[0]) & (f_df.tester_id == k[1])].d_change.values[0])\n",
    "    return np.array(X),np.array(y),np.array(f).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVC_training(X_train, y_train,x_test, y_test, f_test):\n",
    "    if len(X_train.shape) > 2:\n",
    "        X_train = X_train.reshape(list(X_train.shape)[0],-1)\n",
    "        x_test = x_test.reshape(list(x_test.shape)[0],-1)\n",
    "    main_score = []\n",
    "    overal_score = []\n",
    "    for k in ['poly','rbf','linear']:\n",
    "        clf4 = SVC(kernel=k, C=1.5, degree=3, verbose = False)\n",
    "        clf4.fit(X_train, y_train) \n",
    "        res = clf4.predict(x_test)\n",
    "        score = accuracy_score(y_test, res)\n",
    "        print(k + \" score: \" + str(score))\n",
    "        main_score.append(score)\n",
    "        \n",
    "        if (print_conf):\n",
    "            print(classification_report(y_test, res))\n",
    "            print(confusion_matrix(y_test, res))\n",
    "        \n",
    "        if ensemble_06 is True:\n",
    "            for i in range(len(res)):\n",
    "                if (res[i] =='Tag0') or (res[i] == \"Tag6\"):\n",
    "                    binary_res = rf_clf.predict_proba([f_test[i]])[0]\n",
    "                    main_res = clf4.predict_proba(x_test[i])[0]\n",
    "\n",
    "                    binary_res_0 = binary_res[np.where(rf_clf.classes_ == 'Tag0')[0][0]]\n",
    "                    binary_res_6 = binary_res[np.where(rf_clf.classes_ == 'Tag6')[0][0]]\n",
    "                    main_res_0 = main_res[np.where(rf_clf.classes_ == 'Tag0')[0][0]]\n",
    "                    main_res_6 = main_res[np.where(rf_clf.classes_ == 'Tag6')[0][0]]\n",
    "\n",
    "                    r = 1.0/(main_res_0+main_res_6)\n",
    "                    main_res_0 = r*main_res_0\n",
    "                    main_res_6 = r*main_res_6\n",
    "                    \n",
    "                    if binary_res_0 + main_res_0 > binary_res_6+main_res_6:\n",
    "                        res[i] = 'Tag0'\n",
    "                    else:\n",
    "                        res[i] = 'Tag6'\n",
    "            print(\"-----ensembled---------\")\n",
    "            score = accuracy_score(y_test, res)\n",
    "            print(score)\n",
    "            if (print_conf):\n",
    "                print(classification_report(y_test, max_res))\n",
    "                print(confusion_matrix(y_test, max_res))\n",
    "        overal_score.append(score)\n",
    "    return main_score, overal_score\n",
    "            \n",
    "        \n",
    "def RF_training(X_train, y_train,x_test, y_test, f_test):\n",
    "    if len(X_train.shape) > 2:\n",
    "        X_train = X_train.reshape(list(X_train.shape)[0],-1)\n",
    "        x_test = x_test.reshape(list(x_test.shape)[0],-1)\n",
    "\n",
    "        clf4 = RandomForestClassifier(n_estimators=30)\n",
    "\n",
    "        clf4.fit(X_train, y_train) \n",
    "        # joblib.dump(clf4, '../../Results/baseline SVC 0.80 raw data acc with gyro 200 chunk.pkl') \n",
    "        res = clf4.predict(x_test)\n",
    "        score = accuracy_score(y_test, res)\n",
    "        if (print_conf):\n",
    "            print(classification_report(y_test, res))\n",
    "            print(confusion_matrix(y_test, res))\n",
    "        print(\"RF score: \" + str(score))\n",
    "        \n",
    "        if ensemble_06 is True:\n",
    "            for i in range(len(res)):\n",
    "                if (res[i] =='Tag0') or (res[i] == \"Tag6\"):\n",
    "                    binary_res = rf_clf.predict_proba([f_test[i]])[0]\n",
    "                    main_res = clf4.predict_proba(x_test[i])[0]\n",
    "\n",
    "                    binary_res_0 = binary_res[np.where(rf_clf.classes_ == 'Tag0')[0][0]]\n",
    "                    binary_res_6 = binary_res[np.where(rf_clf.classes_ == 'Tag6')[0][0]]\n",
    "                    main_res_0 = main_res[np.where(rf_clf.classes_ == 'Tag0')[0][0]]\n",
    "                    main_res_6 = main_res[np.where(rf_clf.classes_ == 'Tag6')[0][0]]\n",
    "\n",
    "                    r = 1.0/(main_res_0+main_res_6)\n",
    "                    main_res_0 = r*main_res_0\n",
    "                    main_res_6 = r*main_res_6\n",
    "                    \n",
    "                    if binary_res_0 + main_res_0 > binary_res_6+main_res_6:\n",
    "                        res[i] = 'Tag0'\n",
    "                    else:\n",
    "                        res[i] = 'Tag6'\n",
    "\n",
    "            print(\"-----ensembled---------\")\n",
    "            print((accuracy_score(y_test, res)))\n",
    "            if (print_conf):\n",
    "                print(classification_report(y_test, res))\n",
    "                print(confusion_matrix(y_test, res))\n",
    "        return score, (accuracy_score(y_test, res))\n",
    "\n",
    "\n",
    "def DL_training(X_train, y_train,x_test, y_test, f_test):\n",
    "\n",
    "    y = np.concatenate([y_train,y_test])\n",
    "    tag_list = []\n",
    "    for i in range(10):\n",
    "        tag_list.append(['Tag'+str(i),i])\n",
    "    for i in tag_list:\n",
    "        tag_str = i[0]\n",
    "        tag_int = i[1]\n",
    "        y[y==tag_str] = tag_int\n",
    "    y_categorical = to_categorical(y)\n",
    "    \n",
    "    y_train_cate = y_categorical[:len(y_train)]\n",
    "    y_test_cate = y_categorical[len(y_train):]\n",
    "\n",
    "    X_train = X_train.reshape(list(X_train.shape)[0],-1)\n",
    "    x_test = x_test.reshape(list(x_test.shape)[0],-1)\n",
    "    \n",
    "    main_scores = []\n",
    "    overall_scores= []\n",
    "    for i in range(5):\n",
    "        # This returns a tensor\n",
    "        inputs = Input(shape=(X_train.shape[1:]))\n",
    "\n",
    "        # a layer instance is callable on a tensor, and returns a tensor\n",
    "        layer1 = Dense(64, activation='relu')(inputs)\n",
    "        layer2 = Dense(128, activation='relu')(layer1)\n",
    "        layer3 = Dense(64, activation='relu')(layer2)\n",
    "        layer4 = Dense(32, activation='relu')(layer3)\n",
    "        predictions = Dense(10, activation='softmax')(layer4)\n",
    "\n",
    "        mcp = ModelCheckpoint(\"./temp\" + str(i) + \".hdf5\", monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "        model = Model(inputs=inputs, outputs=predictions)\n",
    "#         print(model.summary())\n",
    "        model.compile(optimizer='rmsprop',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        model_his = model.fit(X_train, y_train_cate, batch_size=32, epochs=40, verbose = 0,\n",
    "                              validation_data=(x_test, y_test_cate), callbacks = [mcp]\n",
    "                             )  # starts training\n",
    "\n",
    "        model.load_weights(\"./temp\" + str(i) +\".hdf5\")\n",
    "\n",
    "        res = model.predict(x_test)\n",
    "        predict = np.argmax(res, 1).tolist()\n",
    "        score = accuracy_score(np.argmax(y_test_cate,1), predict)\n",
    "        print(\"DL score:\" +str(score))\n",
    "        main_scores.append(score)\n",
    "        \n",
    "        if(print_conf):\n",
    "            print(classification_report(np.argmax(y_test_cate,1), np.argmax(res, 1)))\n",
    "            print(confusion_matrix(np.argmax(y_test_cate,1), np.argmax(res, 1)))\n",
    "    \n",
    "        if ensemble_06 is True:\n",
    "            for i in range(len(res)):\n",
    "                if (predict[i] ==0) or (predict[i] == 6):\n",
    "                    binary_res = rf_clf.predict_proba([f_test[i]])[0]\n",
    "                    main_res = res[i]\n",
    "\n",
    "                    binary_res_0 = binary_res[np.where(rf_clf.classes_ == 'Tag0')[0][0]]\n",
    "                    binary_res_6 = binary_res[np.where(rf_clf.classes_ == 'Tag6')[0][0]]\n",
    "                    main_res_0 = main_res[0]\n",
    "                    main_res_6 = main_res[6]\n",
    "\n",
    "                    r = 1.0/(main_res_0+main_res_6)\n",
    "                    main_res_0 = r*main_res_0\n",
    "                    main_res_6 = r*main_res_6\n",
    "                    if binary_res_0 + main_res_0 > binary_res_6+main_res_6:\n",
    "                        predict[i] = 0\n",
    "                    else:\n",
    "                        predict[i] = 6\n",
    "                    \n",
    "            print(\"-----ensembled---------\")\n",
    "            score = accuracy_score(np.argmax(y_test_cate,1), predict)\n",
    "            print(score)\n",
    "            overall_scores.append(score)\n",
    "            if(print_conf):\n",
    "                print(np.argmax(y_test_cate,1), predict)\n",
    "            \n",
    "    return main_scores, overall_scores\n",
    "    \n",
    "def CONV1d_training(X_train, y_train,x_test, y_test, f_test):\n",
    "    y = np.concatenate([y_train,y_test])\n",
    "    tag_list = []\n",
    "    for i in range(10):\n",
    "        tag_list.append(['Tag'+str(i),i])\n",
    "    for i in tag_list:\n",
    "        tag_str = i[0]\n",
    "        tag_int = i[1]\n",
    "        y[y==tag_str] = tag_int\n",
    "    y_categorical = to_categorical(y)\n",
    "    \n",
    "    y_train_cate = y_categorical[:len(y_train)]\n",
    "    y_test_cate = y_categorical[len(y_train):]\n",
    "\n",
    "    main_scores=[]\n",
    "    overall_scores=[]\n",
    "    \n",
    "    for i in range(5):\n",
    "        input_val1 = Input(shape=X_train.shape[1:])\n",
    "\n",
    "        con1 = Conv1D(filters=30,kernel_size=5)(input_val1)\n",
    "        max_pooling_1d_1 = MaxPooling1D(pool_size=2, strides=None, padding='valid')(con1)\n",
    "        flat_1 = Flatten()(max_pooling_1d_1)\n",
    "        layer2 = Dense(128, activation='relu')(flat_1)\n",
    "        layer4 = Dense(32, activation='relu')(layer2)\n",
    "        predictions = Dense(y_categorical.shape[-1], activation='softmax')(layer4)\n",
    "\n",
    "        model = Model(inputs = input_val1, outputs=predictions)\n",
    "#         print(model.summary())\n",
    "        mcp = ModelCheckpoint(\"./temp\" + str(i) + \".hdf5\", monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    \n",
    "        model.compile(optimizer='rmsprop',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "        model_his = model.fit(X_train, y_train_cate, batch_size=32, epochs=40, verbose = 0,\n",
    "                              validation_data=(x_test, y_test_cate), callbacks = [mcp]\n",
    "                             )  # starts training\n",
    "\n",
    "        model.load_weights(\"./temp\" + str(i) +\".hdf5\")\n",
    "\n",
    "        res = model.predict(x_test)\n",
    "        predict = np.argmax(res, 1).tolist()\n",
    "        score = accuracy_score(np.argmax(y_test_cate,1), predict)\n",
    "        print(\"CONV score:\" +str(score))\n",
    "        main_scores.append(score)\n",
    "        \n",
    "        if(print_conf):\n",
    "            print(classification_report(np.argmax(y_test_cate,1), np.argmax(res, 1)))\n",
    "            print(confusion_matrix(np.argmax(y_test_cate,1), np.argmax(res, 1)))\n",
    "    \n",
    "        if ensemble_06 is True:\n",
    "            for i in range(len(res)):\n",
    "                if (predict[i] ==0) or (predict[i] == 6):\n",
    "                    binary_res = rf_clf.predict_proba([f_test[i]])[0]\n",
    "                    main_res = res[i]\n",
    "\n",
    "                    binary_res_0 = binary_res[np.where(rf_clf.classes_ == 'Tag0')[0][0]]\n",
    "                    binary_res_6 = binary_res[np.where(rf_clf.classes_ == 'Tag6')[0][0]]\n",
    "                    main_res_0 = main_res[0]\n",
    "                    main_res_6 = main_res[6]\n",
    "\n",
    "                    r = 1.0/(main_res_0+main_res_6)\n",
    "                    main_res_0 = r*main_res_0\n",
    "                    main_res_6 = r*main_res_6\n",
    "                    if binary_res_0 + main_res_0 > binary_res_6+main_res_6:\n",
    "                        predict[i] = 0\n",
    "                    else:\n",
    "                        predict[i] = 6\n",
    "                    \n",
    "            print(\"-----ensembled---------\")\n",
    "            score = accuracy_score(np.argmax(y_test_cate,1), predict)\n",
    "            print(score)\n",
    "            overall_scores.append(score)\n",
    "            if(print_conf):\n",
    "                print(np.argmax(y_test_cate,1), predict)\n",
    "                \n",
    "    return main_scores,overall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [1, 0],\n",
       "       [3, 4],\n",
       "       [3, 0]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2],[1,0]])\n",
    "b=np.array([[3,4],[3,0]])\n",
    "np.concatenate([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_groups = data.groupby(['TagName','tester_id'])\n",
    "all_keys = list(all_groups.groups.keys())\n",
    "np.random.shuffle(all_keys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_06 = True\n",
    "print_conf = False\n",
    "if ensemble_06 is True:\n",
    "    rf_clf = RandomForestClassifier(n_estimators=30,criterion='gini',max_depth=10)\n",
    "    rf_clf.fit(f_train[(y_train=='Tag0') | (y_train=='Tag6')], y_train[(y_train=='Tag0') | (y_train=='Tag6')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf_clf.predict_proba([[0.0]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(0,300):\n",
    "    res.append(rf_clf.predict([[i/100]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N=14\n",
    "X_train, y_train, f_train = get_feature_label(all_groups, all_keys[:-int(len(all_keys)/5)],N)\n",
    "X_test, y_test, f_test= get_feature_label(all_groups, all_keys[-int(len(all_keys)/5):],N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_kernals = ['poly','rbf','linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF score: 0.682692307692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ensembled---------\n",
      "0.701923076923\n",
      "poly score: 0.802884615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:75: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:77: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-d41dda9a05e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m\"RF,\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRF_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msvc_main_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc_overall_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0msvc_kernals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc_main_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc_overall_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-130-e5607f95899e>\u001b[0m in \u001b[0;36mSVC_training\u001b[0;34m(X_train, y_train, x_test, y_test, f_test)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'Tag0'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Tag6\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mbinary_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                     \u001b[0mmain_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0mbinary_res_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Tag0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \"\"\"\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[1;32m    583\u001b[0m                                  \" probability=False\")\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'c_svc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nu_svc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "log=\"\"\n",
    "log+=\"RF,\" + str(RF_training(X_train, y_train, X_test, y_test, f_test)) + \"\\n\"\n",
    "svc_main_res, svc_overall_res = SVC_training(X_train, y_train, X_test, y_test, f_test)\n",
    "for i in range(3):\n",
    "    log+=svc_kernals[i]+\",\"+str(svc_main_res[i])+\",\"+str(svc_overall_res[i])+\"\\n\"\n",
    "log+=\"DL,\" + str(DL_training(X_train, y_train, X_test, y_test, f_test)) + \"\\n\"\n",
    "log+=\"CON1V\" + str(CONV1d_training(X_train, y_train, X_test, y_test, f_test)) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(rf_clf.classes_ == 'Tag6')[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 14\n",
    "X_train, y_train = get_feature_label(train_data, N)\n",
    "x_test, y_test, f_test = get_feature_label_f(test_data, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl = []\n",
    "conv = []\n",
    "for i in range(5):\n",
    "    dl.append(DL_training(X_train, y_train, x_test, y_test, f_test))\n",
    "    conv.append(CONV1d_training(X_train, y_train, x_test, y_test, f_test))\n",
    "    \n",
    "print(np.mean(dl))\n",
    "print(np.mean(conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dl = []\n",
    "conv = []\n",
    "for i in range(5):\n",
    "    dl.append(DL_training(X_train, y_train, x_test, y_test, f_test))\n",
    "#     conv.append(CONV1d_training(X_train, y_train, x_test, y_test, f_test))\n",
    "    \n",
    "print(np.mean(dl))\n",
    "print(np.mean(conv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Determine C for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVC_training_c(X_train, y_train,x_test, y_test, f_test,c):\n",
    "    if len(X_train.shape) > 2:\n",
    "        X_train = X_train.reshape(list(X_train.shape)[0],-1)\n",
    "        x_test = x_test.reshape(list(x_test.shape)[0],-1)\n",
    "    overal_max = []\n",
    "    for k in ['poly','rbf','linear']:\n",
    "        max_score = 0\n",
    "        max_res = []\n",
    "\n",
    "        clf4 = SVC(kernel=k, C=c, degree=3, verbose = False)\n",
    "        clf4.fit(X_train, y_train) \n",
    "        # joblib.dump(clf4, '../../Results/baseline SVC 0.80 raw data acc with gyro 200 chunk.pkl') \n",
    "        res = clf4.predict(x_test)\n",
    "        score = accuracy_score(y_test, res)\n",
    "        if score>max_score:\n",
    "            max_score = score\n",
    "            max_res = res\n",
    "        print(k)\n",
    "        print(\"max score: \" + str(max_score) + \" C = \" + str(c))\n",
    "        \n",
    "#         print(classification_report(y_test, max_res))\n",
    "#         print(confusion_matrix(y_test, max_res))\n",
    "        if ensemble_06 is True:\n",
    "            for i in range(len(max_res)):\n",
    "                if (max_res[i] =='Tag0') or (max_res[i] == \"Tag6\"):\n",
    "                    max_res[i] = rf_clf.predict([f_test[i]])[0]\n",
    "#             print(\"-----ensembled---------\")\n",
    "#             print(classification_report(y_test, max_res))\n",
    "#             print(confusion_matrix(y_test, max_res))\n",
    "        overal_max.append(max_score)\n",
    "    return overal_max\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poly\n",
      "max score: 0.783653846154 C = 0.4\n",
      "rbf\n",
      "max score: 0.673076923077 C = 0.4\n",
      "linear\n",
      "max score: 0.701923076923 C = 0.4\n",
      "poly\n",
      "max score: 0.802884615385 C = 1.4\n",
      "rbf\n",
      "max score: 0.783653846154 C = 1.4\n",
      "linear\n",
      "max score: 0.706730769231 C = 1.4\n",
      "poly\n",
      "max score: 0.802884615385 C = 1.45\n",
      "rbf\n",
      "max score: 0.778846153846 C = 1.45\n",
      "linear\n",
      "max score: 0.706730769231 C = 1.45\n",
      "poly\n",
      "max score: 0.802884615385 C = 1.5\n",
      "rbf\n",
      "max score: 0.783653846154 C = 1.5\n",
      "linear\n",
      "max score: 0.711538461538 C = 1.5\n",
      "poly\n",
      "max score: 0.802884615385 C = 1.55\n",
      "rbf\n",
      "max score: 0.783653846154 C = 1.55\n",
      "linear\n",
      "max score: 0.701923076923 C = 1.55\n",
      "poly\n",
      "max score: 0.798076923077 C = 1.6\n",
      "rbf\n",
      "max score: 0.783653846154 C = 1.6\n",
      "linear\n",
      "max score: 0.701923076923 C = 1.6\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "for i in [0.4,1.4,1.45,1.5,1.55,1.6]:\n",
    "    res.append(SVC_training_c(X_train, y_train, X_test, y_test, f_test,i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
