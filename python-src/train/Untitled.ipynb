{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import linregress\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Flatten, concatenate, Conv2D\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_5models_from_disk():\n",
    "    models = []\n",
    "    for i in range(5):\n",
    "        json_file = open(\"./model\" + str(i) +\".json\", 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(\"temp\" + str(i) +\".hdf5\")\n",
    "        print(\"Loaded model from disk\")\n",
    "\n",
    "        # evaluate loaded model on test data\n",
    "        loaded_model.compile(optimizer='rmsprop',\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "        models.append(loaded_model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shrink_array(array,size):\n",
    "    \n",
    "    ratio = float(len(array)) / float(size+1)\n",
    "    res = []\n",
    "    for i in range(size):\n",
    "        res.append(np.mean(array[math.floor(i*ratio):math.ceil((i+1.0)*ratio)], axis = 0))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unix_timestamp', 'TagName', 'tester_id', 'v_1', 'v_2', 'v_3', 'd_1',\n",
       "       'd_2', 'd_3', 'global_acc1', 'global_acc2', 'global_acc3',\n",
       "       'v_12_square', 'acc_12_square', 'd_12_square'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame.from_csv(\"../../data/database/train_data.csv\")\n",
    "test_data = pd.DataFrame.from_csv(\"../../data/database/test_data.csv\")\n",
    "gesture_features = pd.DataFrame.from_csv(\"../../data/gesture_feature_df.csv\")\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = ['global_acc3','acc_12_square']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_label(data):\n",
    "    groups = data.groupby(['TagName','tester_id'])\n",
    "    keys = groups.groups.keys()\n",
    "    y = []\n",
    "    X = []\n",
    "    gesture = []\n",
    "    for k in keys:\n",
    "        frame_feature = shrink_array(groups.get_group(k)[feature_cols].values, 50)\n",
    "        X.append(frame_feature)\n",
    "        y.append(k[0])\n",
    "        gesture.append(gesture_features.loc[(gesture_features.TagName == k[0]) & (gesture_features.tester_id == k[1]), 'd_change'].values[0])\n",
    "    return np.array(X),np.array(y),np.array(gesture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC_training(X_train, y_train,x_test, y_test, f_test):\n",
    "    if len(X_train.shape) > 2:\n",
    "        X_train = X_train.reshape(list(X_train.shape)[0],-1)\n",
    "        x_test = x_test.reshape(list(x_test.shape)[0],-1)\n",
    "    \n",
    "    for k in ['poly','rbf','linear']:\n",
    "        max_score = 0\n",
    "        max_i = 0\n",
    "        max_res = []\n",
    "        for i in range(1,21):\n",
    "            i = i/2\n",
    "            clf4 = SVC(kernel=k, C=i, degree=3, verbose = True)\n",
    "\n",
    "            clf4.fit(X_train, y_train) \n",
    "            # joblib.dump(clf4, '../../Results/baseline SVC 0.80 raw data acc with gyro 200 chunk.pkl') \n",
    "            res = clf4.predict(x_test)\n",
    "            score = accuracy_score(y_test, res)\n",
    "            if score>max_score:\n",
    "                max_score = score\n",
    "                max_i = i\n",
    "                max_res = res\n",
    "        print(k)\n",
    "        print(\"max score: \" + str(max_score) + \" C = \" + str(max_i))\n",
    "        \n",
    "        print(classification_report(y_test, max_res))\n",
    "        print(confusion_matrix(y_test, max_res))\n",
    "        \n",
    "        for i in range(len(max_res)):\n",
    "            if (max_res[i] =='Tag0') or (max_res[i] == \"Tag6\"):\n",
    "                max_res[i] = rf_clf.predict(f_test[i])[0]\n",
    "            \n",
    "        print(classification_report(y_test, max_res))\n",
    "        print(confusion_matrix(y_test, max_res))\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "def DL_training(X_train, y_train,x_test, y_test, f_test):\n",
    "\n",
    "    y = np.concatenate([y_train,y_test])\n",
    "    tag_list = []\n",
    "    for i in range(10):\n",
    "        tag_list.append(['Tag'+str(i),i])\n",
    "    for i in tag_list:\n",
    "        tag_str = i[0]\n",
    "        tag_int = i[1]\n",
    "        y[y==tag_str] = tag_int\n",
    "    y_categorical = to_categorical(y)\n",
    "    \n",
    "    y_train_cate = y_categorical[:len(y_train)]\n",
    "    y_test_cate = y_categorical[len(y_train):]\n",
    "\n",
    "    X_train = X_train.reshape(list(X_train.shape)[0],-1)\n",
    "    x_test = x_test.reshape(list(x_test.shape)[0],-1)\n",
    "    \n",
    "\n",
    "    for i in range(5):\n",
    "        # This returns a tensor\n",
    "        inputs = Input(shape=(X_train.shape[1:]))\n",
    "\n",
    "        # a layer instance is callable on a tensor, and returns a tensor\n",
    "        layer1 = Dense(64, activation='relu')(inputs)\n",
    "        layer2 = Dense(128, activation='relu')(layer1)\n",
    "        layer3 = Dense(64, activation='relu')(layer2)\n",
    "        layer4 = Dense(32, activation='relu')(layer3)\n",
    "        predictions = Dense(10, activation='softmax')(layer4)\n",
    "\n",
    "        mcp = ModelCheckpoint(\"./temp\" + str(i) + \".hdf5\", monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "        model = Model(inputs=inputs, outputs=predictions)\n",
    "#         print(model.summary())\n",
    "        model.compile(optimizer='rmsprop',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        model_his = model.fit(X_train, y_train_cate, batch_size=32, epochs=40, verbose = 0,\n",
    "                              validation_data=(x_test, y_test_cate), callbacks = [mcp]\n",
    "                             )  # starts training\n",
    "\n",
    "        model_json = model.to_json()\n",
    "        with open(\"./model\" + str(i) +\".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "            \n",
    "    models = load_5models_from_disk()\n",
    "    scores = []\n",
    "    tests = []\n",
    "    predicts = []\n",
    "    f = []\n",
    "    for model in models:\n",
    "        res = model.predict(x_test)\n",
    "        scores.append(accuracy_score(np.argmax(y_test_cate,1), np.argmax(res, 1)))\n",
    "        tests += np.argmax(y_test_cate,1).tolist()\n",
    "        f += f_test.tolist()\n",
    "        predicts += np.argmax(res, 1).tolist()\n",
    "    \n",
    "    print(classification_report(tests, predicts))\n",
    "    print(confusion_matrix(tests, predicts))\n",
    "    \n",
    "    for i in range(len(predicts)):\n",
    "        if (predicts[i] ==0) or (predicts[i] == 6):\n",
    "            if rf_clf.predict(f[i])[0] == 'Tag0':\n",
    "                predicts[i] = 0\n",
    "            else:\n",
    "                predicts[i] = 6\n",
    "\n",
    "    print(classification_report(tests, predicts))\n",
    "    print(confusion_matrix(tests, predicts))\n",
    "    \n",
    "def CONV1d_training(X_train, y_train,x_test, y_test, f_test):\n",
    "    y = np.concatenate([y_train,y_test])\n",
    "    tag_list = []\n",
    "    for i in range(10):\n",
    "        tag_list.append(['Tag'+str(i),i])\n",
    "    for i in tag_list:\n",
    "        tag_str = i[0]\n",
    "        tag_int = i[1]\n",
    "        y[y==tag_str] = tag_int\n",
    "    y_categorical = to_categorical(y)\n",
    "    \n",
    "    y_train_cate = y_categorical[:len(y_train)]\n",
    "    y_test_cate = y_categorical[len(y_train):]\n",
    "\n",
    "    \n",
    "    for i in range(5):\n",
    "        input_val1 = Input(shape=X_train.shape[1:])\n",
    "\n",
    "        con1 = Conv1D(filters=30,kernel_size=10)(input_val1)\n",
    "        max_pooling_1d_1 = MaxPooling1D(pool_size=2, strides=None, padding='valid')(con1)\n",
    "        flat_1 = Flatten()(max_pooling_1d_1)\n",
    "        layer2 = Dense(128, activation='relu')(flat_1)\n",
    "        layer4 = Dense(32, activation='relu')(layer2)\n",
    "        predictions = Dense(y_categorical.shape[-1], activation='softmax')(layer4)\n",
    "\n",
    "        model = Model(inputs = input_val1, outputs=predictions)\n",
    "#         print(model.summary())\n",
    "        mcp = ModelCheckpoint(\"./temp\" + str(i) + \".hdf5\", monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    \n",
    "        model.compile(optimizer='rmsprop',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "        model_his = model.fit(X_train, y_train_cate, batch_size=32, epochs=40, verbose = 0,\n",
    "                              validation_data=(x_test, y_test_cate), callbacks = [mcp]\n",
    "                             )  # starts training\n",
    "\n",
    "        model_json = model.to_json()\n",
    "        with open(\"./model\" + str(i) +\".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "            \n",
    "    models = load_5models_from_disk()\n",
    "    scores = []\n",
    "    tests = []\n",
    "    predicts = []\n",
    "    f = []\n",
    "    \n",
    "    for model in models:\n",
    "        res = model.predict(x_test)\n",
    "        scores.append(accuracy_score(np.argmax(y_test_cate,1), np.argmax(res, 1)))\n",
    "        tests += np.argmax(y_test_cate,1).tolist()\n",
    "        predicts += np.argmax(res, 1).tolist()\n",
    "        f += f_test.tolist()\n",
    "        \n",
    "    print(classification_report(tests, predicts))\n",
    "    print(confusion_matrix(tests, predicts))\n",
    "    \n",
    "    for i in range(len(predicts)):\n",
    "        if (predicts[i] ==0) or (predicts[i] == 6):\n",
    "            if rf_clf.predict(f[i])[0] == 'Tag0':\n",
    "                predicts[i] = 0\n",
    "            else:\n",
    "                predicts[i] = 6\n",
    "\n",
    "    print(classification_report(tests, predicts))\n",
    "    print(confusion_matrix(tests, predicts))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# def plot_gesture(gesture):\n",
    "#     for i in range(gesture.shape[1]):\n",
    "#         plt.plot(gesture[:,i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(830, 50, 2)\n",
      "(830,)\n",
      "(830,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, f_train = get_feature_label(train_data)\n",
    "x_test, y_test, f_test = get_feature_label(test_data)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(f_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "y_train_06 = y_train[(y_train=='Tag0') | (y_train=='Tag6')]\n",
    "f_train_06 = f_train[(y_train=='Tag0') | (y_train=='Tag6')]\n",
    "if len(f_train_06.shape) == 1:\n",
    "    rf_clf.fit(f_train_06.reshape(len(f_train_06),1),y_train_06)\n",
    "else:\n",
    "    rf_clf.fit(f_train_06,y_train_06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]poly\n",
      "max score: 0.804761904762 C = 0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Tag0       0.71      0.81      0.76        21\n",
      "       Tag1       0.94      0.81      0.87        21\n",
      "       Tag2       0.90      0.86      0.88        21\n",
      "       Tag3       0.80      0.95      0.87        21\n",
      "       Tag4       0.89      0.81      0.85        21\n",
      "       Tag5       0.64      0.76      0.70        21\n",
      "       Tag6       0.78      0.67      0.72        21\n",
      "       Tag7       0.83      0.90      0.86        21\n",
      "       Tag8       0.89      0.76      0.82        21\n",
      "       Tag9       0.75      0.71      0.73        21\n",
      "\n",
      "avg / total       0.81      0.80      0.81       210\n",
      "\n",
      "[[17  0  0  0  0  1  2  0  0  1]\n",
      " [ 1 17  1  0  0  1  0  0  0  1]\n",
      " [ 0  1 18  1  0  1  0  0  0  0]\n",
      " [ 0  0  0 20  0  0  0  0  0  1]\n",
      " [ 1  0  0  1 17  0  0  0  0  2]\n",
      " [ 0  0  0  1  0 16  1  1  2  0]\n",
      " [ 5  0  0  1  0  1 14  0  0  0]\n",
      " [ 0  0  0  1  0  1  0 19  0  0]\n",
      " [ 0  0  1  0  0  3  1  0 16  0]\n",
      " [ 0  0  0  0  2  1  0  3  0 15]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Tag0       0.85      0.81      0.83        21\n",
      "       Tag1       0.94      0.81      0.87        21\n",
      "       Tag2       0.90      0.86      0.88        21\n",
      "       Tag3       0.80      0.95      0.87        21\n",
      "       Tag4       0.89      0.81      0.85        21\n",
      "       Tag5       0.64      0.76      0.70        21\n",
      "       Tag6       0.77      0.81      0.79        21\n",
      "       Tag7       0.83      0.90      0.86        21\n",
      "       Tag8       0.89      0.76      0.82        21\n",
      "       Tag9       0.75      0.71      0.73        21\n",
      "\n",
      "avg / total       0.83      0.82      0.82       210\n",
      "\n",
      "[[17  0  0  0  0  1  2  0  0  1]\n",
      " [ 0 17  1  0  0  1  1  0  0  1]\n",
      " [ 0  1 18  1  0  1  0  0  0  0]\n",
      " [ 0  0  0 20  0  0  0  0  0  1]\n",
      " [ 0  0  0  1 17  0  1  0  0  2]\n",
      " [ 0  0  0  1  0 16  1  1  2  0]\n",
      " [ 2  0  0  1  0  1 17  0  0  0]\n",
      " [ 0  0  0  1  0  1  0 19  0  0]\n",
      " [ 1  0  1  0  0  3  0  0 16  0]\n",
      " [ 0  0  0  0  2  1  0  3  0 15]]\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]rbf\n",
      "max score: 0.714285714286 C = 1.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Tag0       0.67      0.38      0.48        21\n",
      "       Tag1       1.00      0.86      0.92        21\n",
      "       Tag2       0.94      0.76      0.84        21\n",
      "       Tag3       0.85      0.81      0.83        21\n",
      "       Tag4       0.94      0.81      0.87        21\n",
      "       Tag5       0.32      0.90      0.47        21\n",
      "       Tag6       0.63      0.57      0.60        21\n",
      "       Tag7       1.00      0.76      0.86        21\n",
      "       Tag8       0.93      0.62      0.74        21\n",
      "       Tag9       0.88      0.67      0.76        21\n",
      "\n",
      "avg / total       0.82      0.71      0.74       210\n",
      "\n",
      "[[ 8  0  0  0  0  7  6  0  0  0]\n",
      " [ 0 18  0  1  0  1  0  0  0  1]\n",
      " [ 0  0 16  1  0  4  0  0  0  0]\n",
      " [ 0  0  0 17  0  4  0  0  0  0]\n",
      " [ 0  0  0  0 17  4  0  0  0  0]\n",
      " [ 1  0  0  1  0 19  0  0  0  0]\n",
      " [ 3  0  0  0  0  5 12  0  0  1]\n",
      " [ 0  0  0  0  0  4  0 16  1  0]\n",
      " [ 0  0  1  0  0  6  1  0 13  0]\n",
      " [ 0  0  0  0  1  6  0  0  0 14]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Tag0       0.87      0.62      0.72        21\n",
      "       Tag1       1.00      0.86      0.92        21\n",
      "       Tag2       0.94      0.76      0.84        21\n",
      "       Tag3       0.85      0.81      0.83        21\n",
      "       Tag4       0.94      0.81      0.87        21\n",
      "       Tag5       0.32      0.90      0.47        21\n",
      "       Tag6       0.88      0.67      0.76        21\n",
      "       Tag7       1.00      0.76      0.86        21\n",
      "       Tag8       0.93      0.62      0.74        21\n",
      "       Tag9       0.88      0.67      0.76        21\n",
      "\n",
      "avg / total       0.86      0.75      0.78       210\n",
      "\n",
      "[[13  0  0  0  0  7  1  0  0  0]\n",
      " [ 0 18  0  1  0  1  0  0  0  1]\n",
      " [ 0  0 16  1  0  4  0  0  0  0]\n",
      " [ 0  0  0 17  0  4  0  0  0  0]\n",
      " [ 0  0  0  0 17  4  0  0  0  0]\n",
      " [ 0  0  0  1  0 19  1  0  0  0]\n",
      " [ 1  0  0  0  0  5 14  0  0  1]\n",
      " [ 0  0  0  0  0  4  0 16  1  0]\n",
      " [ 1  0  1  0  0  6  0  0 13  0]\n",
      " [ 0  0  0  0  1  6  0  0  0 14]]\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]linear\n",
      "max score: 0.704761904762 C = 0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Tag0       0.38      0.43      0.40        21\n",
      "       Tag1       0.87      0.95      0.91        21\n",
      "       Tag2       0.72      0.86      0.78        21\n",
      "       Tag3       0.65      0.71      0.68        21\n",
      "       Tag4       0.95      0.90      0.93        21\n",
      "       Tag5       0.75      0.57      0.65        21\n",
      "       Tag6       0.58      0.71      0.64        21\n",
      "       Tag7       0.81      0.62      0.70        21\n",
      "       Tag8       0.67      0.48      0.56        21\n",
      "       Tag9       0.77      0.81      0.79        21\n",
      "\n",
      "avg / total       0.71      0.70      0.70       210\n",
      "\n",
      "[[ 9  0  0  0  0  0  8  0  3  1]\n",
      " [ 0 20  0  0  0  0  0  0  0  1]\n",
      " [ 0  0 18  2  0  1  0  0  0  0]\n",
      " [ 0  0  5 15  0  0  0  0  1  0]\n",
      " [ 1  0  0  0 19  0  0  1  0  0]\n",
      " [ 3  0  0  5  0 12  0  0  1  0]\n",
      " [ 6  0  0  0  0  0 15  0  0  0]\n",
      " [ 0  3  1  0  0  1  0 13  0  3]\n",
      " [ 5  0  1  0  0  2  3  0 10  0]\n",
      " [ 0  0  0  1  1  0  0  2  0 17]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Tag0       0.56      0.71      0.63        21\n",
      "       Tag1       0.87      0.95      0.91        21\n",
      "       Tag2       0.72      0.86      0.78        21\n",
      "       Tag3       0.65      0.71      0.68        21\n",
      "       Tag4       0.95      0.90      0.93        21\n",
      "       Tag5       0.75      0.57      0.65        21\n",
      "       Tag6       0.78      0.86      0.82        21\n",
      "       Tag7       0.81      0.62      0.70        21\n",
      "       Tag8       0.67      0.48      0.56        21\n",
      "       Tag9       0.77      0.81      0.79        21\n",
      "\n",
      "avg / total       0.75      0.75      0.74       210\n",
      "\n",
      "[[15  0  0  0  0  0  2  0  3  1]\n",
      " [ 0 20  0  0  0  0  0  0  0  1]\n",
      " [ 0  0 18  2  0  1  0  0  0  0]\n",
      " [ 0  0  5 15  0  0  0  0  1  0]\n",
      " [ 1  0  0  0 19  0  0  1  0  0]\n",
      " [ 1  0  0  5  0 12  2  0  1  0]\n",
      " [ 3  0  0  0  0  0 18  0  0  0]\n",
      " [ 0  3  1  0  0  1  0 13  0  3]\n",
      " [ 7  0  1  0  0  2  1  0 10  0]\n",
      " [ 0  0  0  1  1  0  0  2  0 17]]\n"
     ]
    }
   ],
   "source": [
    "SVC_training(X_train, y_train, x_test, y_test, f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Loaded model from disk\n",
      "Loaded model from disk\n",
      "Loaded model from disk\n",
      "Loaded model from disk\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.82      0.77       105\n",
      "          1       0.94      0.96      0.95       105\n",
      "          2       0.92      0.93      0.93       105\n",
      "          3       0.85      0.97      0.91       105\n",
      "          4       0.96      0.95      0.96       105\n",
      "          5       0.90      0.76      0.82       105\n",
      "          6       0.77      0.74      0.76       105\n",
      "          7       0.90      0.90      0.90       105\n",
      "          8       0.94      0.87      0.90       105\n",
      "          9       0.91      0.90      0.90       105\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1050\n",
      "\n",
      "[[ 86   0   0   0   0   0  17   0   0   2]\n",
      " [  0 101   0   0   0   0   0   0   0   4]\n",
      " [  0   0  98   4   0   1   1   0   1   0]\n",
      " [  0   0   3 102   0   0   0   0   0   0]\n",
      " [  0   0   0   0 100   0   0   5   0   0]\n",
      " [  3   1   2   9   1  80   1   1   5   2]\n",
      " [ 26   0   0   0   0   0  78   0   0   1]\n",
      " [  0   6   1   1   0   0   2  95   0   0]\n",
      " [  2   0   2   1   0   7   2   0  91   0]\n",
      " [  0   0   0   3   3   1   0   4   0  94]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.89      0.86       105\n",
      "          1       0.94      0.96      0.95       105\n",
      "          2       0.92      0.93      0.93       105\n",
      "          3       0.85      0.97      0.91       105\n",
      "          4       0.96      0.95      0.96       105\n",
      "          5       0.90      0.76      0.82       105\n",
      "          6       0.84      0.85      0.84       105\n",
      "          7       0.90      0.90      0.90       105\n",
      "          8       0.94      0.87      0.90       105\n",
      "          9       0.91      0.90      0.90       105\n",
      "\n",
      "avg / total       0.90      0.90      0.90      1050\n",
      "\n",
      "[[ 93   0   0   0   0   0  10   0   0   2]\n",
      " [  0 101   0   0   0   0   0   0   0   4]\n",
      " [  0   0  98   4   0   1   1   0   1   0]\n",
      " [  0   0   3 102   0   0   0   0   0   0]\n",
      " [  0   0   0   0 100   0   0   5   0   0]\n",
      " [  0   1   2   9   1  80   4   1   5   2]\n",
      " [ 15   0   0   0   0   0  89   0   0   1]\n",
      " [  0   6   1   1   0   0   2  95   0   0]\n",
      " [  4   0   2   1   0   7   0   0  91   0]\n",
      " [  0   0   0   3   3   1   0   4   0  94]]\n"
     ]
    }
   ],
   "source": [
    "DL_training(X_train, y_train, x_test, y_test, f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Loaded model from disk\n",
      "Loaded model from disk\n",
      "Loaded model from disk\n",
      "Loaded model from disk\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.83      0.81       105\n",
      "          1       0.99      0.94      0.97       105\n",
      "          2       0.92      0.95      0.93       105\n",
      "          3       0.90      0.99      0.95       105\n",
      "          4       0.95      0.95      0.95       105\n",
      "          5       0.88      0.82      0.85       105\n",
      "          6       0.80      0.80      0.80       105\n",
      "          7       0.99      0.96      0.98       105\n",
      "          8       0.95      0.85      0.89       105\n",
      "          9       0.88      0.93      0.91       105\n",
      "\n",
      "avg / total       0.90      0.90      0.90      1050\n",
      "\n",
      "[[ 87   0   0   0   0   0  17   0   0   1]\n",
      " [  0  99   0   0   0   0   0   0   0   6]\n",
      " [  0   0 100   5   0   0   0   0   0   0]\n",
      " [  0   0   1 104   0   0   0   0   0   0]\n",
      " [  0   0   0   0 100   0   0   0   0   5]\n",
      " [  3   0   3   6   1  86   1   0   5   0]\n",
      " [ 20   0   0   0   0   1  84   0   0   0]\n",
      " [  0   1   1   0   0   0   2 101   0   0]\n",
      " [  1   0   3   0   0  10   1   0  89   1]\n",
      " [  0   0   1   0   4   1   0   1   0  98]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.90      0.87       105\n",
      "          1       0.99      0.94      0.97       105\n",
      "          2       0.92      0.95      0.93       105\n",
      "          3       0.90      0.99      0.95       105\n",
      "          4       0.95      0.95      0.95       105\n",
      "          5       0.88      0.82      0.85       105\n",
      "          6       0.85      0.86      0.85       105\n",
      "          7       0.99      0.96      0.98       105\n",
      "          8       0.95      0.85      0.89       105\n",
      "          9       0.88      0.93      0.91       105\n",
      "\n",
      "avg / total       0.92      0.92      0.92      1050\n",
      "\n",
      "[[ 94   0   0   0   0   0  10   0   0   1]\n",
      " [  0  99   0   0   0   0   0   0   0   6]\n",
      " [  0   0 100   5   0   0   0   0   0   0]\n",
      " [  0   0   1 104   0   0   0   0   0   0]\n",
      " [  0   0   0   0 100   0   0   0   0   5]\n",
      " [  0   0   3   6   1  86   4   0   5   0]\n",
      " [ 14   0   0   0   0   1  90   0   0   0]\n",
      " [  0   1   1   0   0   0   2 101   0   0]\n",
      " [  2   0   3   0   0  10   0   0  89   1]\n",
      " [  0   0   1   0   4   1   0   1   0  98]]\n"
     ]
    }
   ],
   "source": [
    "CONV1d_training(X_train, y_train, x_test, y_test, f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gesture_features.groupby(['TagName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag0\n",
      "0.0251633133074\n",
      "0.172669880427\n",
      "Tag1\n",
      "-0.533930148824\n",
      "0.185776339633\n",
      "Tag2\n",
      "-0.492384350953\n",
      "0.263275811534\n",
      "Tag3\n",
      "-0.634171660652\n",
      "0.361112519218\n",
      "Tag4\n",
      "-0.594274538652\n",
      "0.257722142262\n",
      "Tag5\n",
      "-0.185724596056\n",
      "0.354015164845\n",
      "Tag6\n",
      "-0.229694763636\n",
      "0.300580473984\n",
      "Tag7\n",
      "-0.560041225895\n",
      "0.216076053837\n",
      "Tag8\n",
      "-0.0230429142299\n",
      "0.233432037176\n",
      "Tag9\n",
      "-0.572249550629\n",
      "0.258339263312\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Tag\" + str(i))\n",
    "    v = g.get_group(\"Tag\" + str(i)).d_change.values\n",
    "    print(np.mean(v))\n",
    "    print(np.std(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
