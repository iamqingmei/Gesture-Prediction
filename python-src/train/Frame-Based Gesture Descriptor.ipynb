{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Tag0': 352461,\n",
       "         'Tag1': 272234,\n",
       "         'Tag2': 377420,\n",
       "         'Tag3': 398370,\n",
       "         'Tag4': 428642,\n",
       "         'Tag5': 435086,\n",
       "         'Tag6': 358288,\n",
       "         'Tag7': 315266,\n",
       "         'Tag8': 431390,\n",
       "         'Tag9': 381880})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_data = pd.DataFrame.from_csv(\"../../data/database/sensor_data.csv\")\n",
    "sensor_data = sensor_data[~((sensor_data.TagName == 'Start1') | (sensor_data.TagName == 'Start2'))]\n",
    "Counter(sensor_data.TagName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data_acc = sensor_data[(sensor_data.SENSORTYPE == 1)]\n",
    "# tag_id_groupby = sensor_data_acc_tag12.groupby(['TagName', 'tester_id'])\n",
    "tag_id_groupby_acc = sensor_data_acc.groupby(['TagName', 'tester_id'])\n",
    "tag_id_dict = tag_id_groupby_acc.groups\n",
    "y = list(tag_id_dict.keys())\n",
    "y = [i[0] for i in y]\n",
    "y = np.array(y)\n",
    "\n",
    "sensor_data_magnetic = sensor_data[(sensor_data.SENSORTYPE == 2)]\n",
    "tag_id_groupby_magnetic = sensor_data_magnetic.groupby(['TagName', 'tester_id'])\n",
    "\n",
    "sensor_data_orientation = sensor_data[(sensor_data.SENSORTYPE == 3)]\n",
    "tag_id_groupby_orientation = sensor_data_orientation.groupby(['TagName', 'tester_id'])\n",
    "\n",
    "sensor_data_gyro = sensor_data[(sensor_data.SENSORTYPE == 4)]\n",
    "tag_id_groupby_gyro = sensor_data_gyro.groupby(['TagName', 'tester_id'])\n",
    "\n",
    "sensor_data_gravity = sensor_data[(sensor_data.SENSORTYPE == 9)]\n",
    "tag_id_groupby_gravity = sensor_data_gravity.groupby(['TagName', 'tester_id'])\n",
    "\n",
    "sensor_data_quaternion = sensor_data[(sensor_data.SENSORTYPE == 11)]\n",
    "tag_id_groupby_quaternion = sensor_data_quaternion.groupby(['TagName', 'tester_id'])\n",
    "\n",
    "sensor_data_tilt = sensor_data[(sensor_data.SENSORTYPE == 26)]\n",
    "tag_id_groupby_tilt = sensor_data_tilt.groupby(['TagName', 'tester_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there will be 9 frames, frame0 to frame8\n",
    "# There will be 10 segments\n",
    "N_frame_no = 15\n",
    "\n",
    "test_percent = 0.1 # 10% samples are used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gesture_features(accs):\n",
    "#     for i in range(accs.shape[0]): # x, y, z\n",
    "#         accs[i] = min_max_normalization(accs[i], np.min(accs[i]), np.max(accs[i]))\n",
    "        \n",
    "    if N_frame_no > 1:\n",
    "        Ls = math.floor(len(accs)/ (N_frame_no + 1))\n",
    "        segments = None\n",
    "        for i in range(N_frame_no + 1):\n",
    "            if segments is None:\n",
    "                segments = np.array([accs[i*Ls:(i+1)*Ls]])\n",
    "            else:\n",
    "                segments = np.append(segments, np.array([accs[i*Ls:(i+1)*Ls]]), axis=0)\n",
    "\n",
    "        frames = None\n",
    "        for i in range(N_frame_no):\n",
    "            cur_frame = segments[i:i+2]\n",
    "            cur_frame = cur_frame.reshape((cur_frame.shape[0]*cur_frame.shape[1],cur_frame.shape[2]))\n",
    "            if frames is None:\n",
    "                frames = np.array([cur_frame])\n",
    "            else:\n",
    "                frames = np.append(frames, np.array([cur_frame]), axis = 0)\n",
    "\n",
    "        \n",
    "        return np.array([frame_features(f) for f in frames])\n",
    "    else:\n",
    "        return frame_features(accs).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frame_features(cur_frame):\n",
    "    dft_cur_frame = np.fft.fftn(cur_frame)\n",
    "    \n",
    "    mean_cur_frame = dft_cur_frame[0]\n",
    "\n",
    "    energy_cur_frame=[]\n",
    "    for T in range(cur_frame.shape[1]): #x,y,z\n",
    "        T_sum = 0\n",
    "        for i in range(1,len(cur_frame)):\n",
    "            T_sum += math.pow(abs(dft_cur_frame[i,T]),2)\n",
    "\n",
    "        energy_cur_frame.append(T_sum / (len(cur_frame)-1))\n",
    "    energy_cur_frame = np.array(energy_cur_frame)\n",
    "    \n",
    "    entropy_cur_frame = []\n",
    "    for T in range(cur_frame.shape[1]): #x,y,z\n",
    "        T_sum = 0\n",
    "        entropy_sum = 0\n",
    "        for i in dft_cur_frame[1:,T]:\n",
    "            T_sum += abs(i)\n",
    "            \n",
    "        for m in dft_cur_frame[1:,T]:\n",
    "            p_m_T = abs(m)/T_sum\n",
    "            entropy_sum += p_m_T*math.log(1/p_m_T)\n",
    "\n",
    "        entropy_cur_frame.append(entropy_sum)\n",
    "    entropy_cur_frame = np.array(entropy_cur_frame)\n",
    "    \n",
    "\n",
    "    std_cur_frame = []\n",
    "    for T in range(cur_frame.shape[1]): #x,y,z\n",
    "        std_cur_frame.append(np.std(cur_frame))\n",
    "    std_cur_frame = np.array(std_cur_frame)\n",
    "    \n",
    "    coorelation_cur_frame = []\n",
    "    for T1,T2 in [(0,1),(1,2),(0,2)]:\n",
    "        coorelation_cur_frame.append(np.correlate(cur_frame[:,T1], cur_frame[:,T2])[0])\n",
    "    coorelation_cur_frame = np.array(coorelation_cur_frame)\n",
    "    \n",
    "    return np.concatenate((mean_cur_frame, energy_cur_frame, entropy_cur_frame, std_cur_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shrink_array(array,size):\n",
    "    \n",
    "    ratio = float(len(array)) / float(size+1)\n",
    "    res = []\n",
    "    for i in range(size):\n",
    "        res.append(np.mean(array[math.floor(i*ratio):math.ceil((i+1.0)*ratio)], axis = 0))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for key in list(tag_id_dict.keys()):\n",
    "    frame_feature = gesture_features(tag_id_groupby_acc.get_group(key)[['VALUES1', 'VALUES2', 'VALUES3']].values)\n",
    "#     acc_feature = shrink_array(tag_id_groupby_acc.get_group(key)[['VALUES1','VALUES2', 'VALUES3']].values, 200).reshape(-1)\n",
    "#     t = pd.to_datetime(tag_id_groupby_acc.get_group(key)['TIMESTAMP']).values\n",
    "#     time_dif = (np.max(t) - np.min(t)).item()/1000000000\n",
    "    X.append(frame_feature)\n",
    "#     X.append(np.concatenate((acc_feature, np.array([time_dif]))))\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 15, 12)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:382: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  array = np.array(array, dtype=dtype, order=order, copy=copy)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:382: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  array = np.array(array, dtype=dtype, order=order, copy=copy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:382: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  array = np.array(array, dtype=dtype, order=order, copy=copy)\n",
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:382: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  array = np.array(array, dtype=dtype, order=order, copy=copy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][ 0.61818182  0.61818182  0.49047619  0.68095238  0.5       ]\n",
      "0.581558441558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:382: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  array = np.array(array, dtype=dtype, order=order, copy=copy)\n"
     ]
    }
   ],
   "source": [
    "# idx_list = list(range(len(X)))\n",
    "# np.random.shuffle(idx_list)\n",
    "# train_idx = idx_list[:math.floor(len(X) * (1- test_percent))]\n",
    "# test_idx = idx_list[math.floor(len(X) * (1- test_percent)):]\n",
    "\n",
    "# # y[y == 'Tag2'] = 2\n",
    "# # y[y == 'Tag1'] = 1\n",
    "\n",
    "# train_x = X[train_idx]\n",
    "# train_y = y[train_idx]\n",
    "# test_x = X[test_idx]\n",
    "# test_y = y[test_idx]\n",
    "\n",
    "clf4 = SVC(kernel='poly', C=1, degree=3, verbose = True)\n",
    "# clf4.fit(train_x, train_y) \n",
    "# joblib.dump(clf4, '../../Results/baseline SVC 0.80 raw data acc with gyro 200 chunk.pkl') \n",
    "# print(classification_report(test_y, clf4.predict(test_x)))\n",
    "if len(X.shape) > 2:\n",
    "    res = cross_val_score(clf4, X.reshape(list(X.shape)[0],-1), y, cv = 5)\n",
    "else:\n",
    "    res = cross_val_score(clf4, X, y, cv=5)\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
