{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Tag0': 352461,\n",
       "         'Tag1': 272234,\n",
       "         'Tag2': 377420,\n",
       "         'Tag3': 398370,\n",
       "         'Tag4': 428642,\n",
       "         'Tag5': 435086,\n",
       "         'Tag6': 358288,\n",
       "         'Tag7': 315266,\n",
       "         'Tag8': 431390,\n",
       "         'Tag9': 381880})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_data = pd.DataFrame.from_csv(\"../../data/database/sensor_data.csv\")\n",
    "sensor_data = sensor_data[~((sensor_data.TagName == 'Start1') | (sensor_data.TagName == 'Start2'))]\n",
    "Counter(sensor_data.TagName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_acc_feature = pd.DataFrame.from_csv(\"../../data/linear_accuracy_features_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unix_timestamp</th>\n",
       "      <th>TagName</th>\n",
       "      <th>tester_id</th>\n",
       "      <th>linear_distance_x</th>\n",
       "      <th>linear_distance_y</th>\n",
       "      <th>linear_distance_z</th>\n",
       "      <th>linear_velocity_x</th>\n",
       "      <th>linear_velocity_y</th>\n",
       "      <th>linear_velocity_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.515398e+09</td>\n",
       "      <td>Tag0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.515398e+09</td>\n",
       "      <td>Tag0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-4.668691e-08</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.001068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.515398e+09</td>\n",
       "      <td>Tag0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>4.726809e-08</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>-0.002288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.515398e+09</td>\n",
       "      <td>Tag0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>2.830433e-07</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>-0.003878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.515398e+09</td>\n",
       "      <td>Tag0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-1.041740e-06</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>-0.000423</td>\n",
       "      <td>-0.005201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unix_timestamp TagName  tester_id  linear_distance_x  linear_distance_y  \\\n",
       "0    1.515398e+09    Tag0        0.0           0.000000       0.000000e+00   \n",
       "1    1.515398e+09    Tag0        0.0           0.000004      -4.668691e-08   \n",
       "2    1.515398e+09    Tag0        0.0           0.000017       4.726809e-08   \n",
       "3    1.515398e+09    Tag0        0.0           0.000043       2.830433e-07   \n",
       "4    1.515398e+09    Tag0        0.0           0.000073      -1.041740e-06   \n",
       "\n",
       "   linear_distance_z  linear_velocity_x  linear_velocity_y  linear_velocity_z  \n",
       "0           0.000000           0.000000           0.000000           0.000000  \n",
       "1          -0.000003           0.001760          -0.000019          -0.001068  \n",
       "2          -0.000011           0.003328           0.000103          -0.002288  \n",
       "3          -0.000029           0.005259          -0.000093          -0.003878  \n",
       "4          -0.000052           0.006686          -0.000423          -0.005201  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_acc_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def min_max_normalization(feature, mini = None, maxi = None):\n",
    "    if ((maxi is None) or (mini is None)):\n",
    "        maxi = np.max(feature)\n",
    "        mini = np.min(feature)\n",
    "#         print(maxi)\n",
    "#         print(mini)\n",
    "    else:\n",
    "        if (maxi == mini):\n",
    "            # all the values is same:\n",
    "            return np.array([1] * feature.size).reshape(feature.shape)\n",
    "        if type(feature) == list:\n",
    "            feature = np.array(feature)\n",
    "        feature[feature < mini] = mini\n",
    "        feature[feature > maxi] = maxi\n",
    "\n",
    "    feature = ((feature - mini) / (maxi - mini))\n",
    "        \n",
    "    \n",
    "    return feature\n",
    "\n",
    "\n",
    "if os.path.exists(\"../../data/database/normalized_sensor_data.csv\") is False:\n",
    "    load_original_data()\n",
    "    percentile_df = pd.DataFrame.from_csv(\"../../Results/percentiles_sensortype.txt\")\n",
    "\n",
    "    normalized_sensor_data = pd.DataFrame(columns=sensor_data.columns,index=sensor_data.index)\n",
    "    normalized_sensor_data.loc[:,'SENSORTYPE'] = sensor_data['SENSORTYPE'].values\n",
    "    normalized_sensor_data.loc[:,'TagName'] = sensor_data['TagName'].values\n",
    "    normalized_sensor_data.loc[:,'tester_id'] = sensor_data['tester_id'].values\n",
    "    normalized_sensor_data.loc[:,'TIMESTAMP'] = sensor_data['TIMESTAMP'].values\n",
    "#     for i in range(len(percentile_df)):\n",
    "#         cur = percentile_df.iloc[i].values\n",
    "#         sensor = cur[0]\n",
    "#         val = ['VALUES1','VALUES2', 'VALUES3']\n",
    "#         p97 = cur[1]\n",
    "#         p03 = cur[2]\n",
    "#         normalized_sensor_data.loc[(sensor_data.SENSORTYPE == sensor), val] = min_max_normalization(sensor_data[(sensor_data.SENSORTYPE == sensor)][val].values, p03, p97)\n",
    "#         print(\"processing: \" + str(cur))\n",
    "    for sensor in (percentile_df[' SENSORTYPE'].values):\n",
    "        if sensor == 26:\n",
    "            continue\n",
    "        val = ['VALUES1','VALUES2', 'VALUES3']\n",
    "        print(\"processing sensortype: \" + str(sensor))\n",
    "\n",
    "        data = sensor_data[sensor_data.SENSORTYPE == sensor][val].values.reshape(-1,1)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(data)\n",
    "        normalized_sensor_data.loc[(sensor_data.SENSORTYPE == sensor), val] = scaler.transform(data).reshape(int(data.size / 3),3)\n",
    "\n",
    "#     normalized_sensor_data.to_csv(\"../../data/database/normalized_sensor_data.csv\")\n",
    "#     del sensor_data\n",
    "else:\n",
    "    normalized_sensor_data = pd.DataFrame.from_csv(\"../../data/database/normalized_sensor_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sensor_data_option = \"Normalize\"\n",
    "if sensor_data_option == \"Normalize\":\n",
    "    # tag_id_groupby = sensor_data_acc_tag12.groupby(['TagName', 'tester_id'])\n",
    "    tag_id_groupby_acc = normalized_sensor_data[(normalized_sensor_data.SENSORTYPE == 1)].groupby(['TagName', 'tester_id'])\n",
    "\n",
    "    tag_id_groupby_magnetic = normalized_sensor_data[(normalized_sensor_data.SENSORTYPE == 2)].groupby(['TagName', 'tester_id'])\n",
    "\n",
    "    tag_id_groupby_orientation = normalized_sensor_data[(normalized_sensor_data.SENSORTYPE == 3)].groupby(['TagName', 'tester_id'])\n",
    "\n",
    "    tag_id_groupby_gyro = normalized_sensor_data[(normalized_sensor_data.SENSORTYPE == 4)].groupby(['TagName', 'tester_id'])\n",
    "\n",
    "    tag_id_groupby_gravity = normalized_sensor_data[(normalized_sensor_data.SENSORTYPE == 9)].groupby(['TagName', 'tester_id'])\n",
    "    \n",
    "    tag_id_linear_acc = normalized_sensor_data[(normalized_sensor_data.SENSORTYPE == 10)].groupby(['TagName', 'tester_id'])\n",
    "\n",
    "    tag_id_groupby_quaternion = normalized_sensor_data[(normalized_sensor_data.SENSORTYPE == 11)].groupby(['TagName', 'tester_id'])\n",
    "\n",
    "    tag_id_groupby_tilt = normalized_sensor_data[(normalized_sensor_data.SENSORTYPE == 26)].groupby(['TagName', 'tester_id'])\n",
    "else:\n",
    "\n",
    "    # tag_id_groupby = sensor_data_acc_tag12.groupby(['TagName', 'tester_id'])\n",
    "    tag_id_groupby_acc = sensor_data[(sensor_data.SENSORTYPE == 1)].groupby(['TagName', 'tester_id'])\n",
    "\n",
    "    tag_id_groupby_magnetic = sensor_data[(sensor_data.SENSORTYPE == 2)].groupby(['TagName', 'tester_id'])\n",
    "\n",
    "    tag_id_groupby_orientation = sensor_data[(sensor_data.SENSORTYPE == 3)].groupby(['TagName', 'tester_id'])\n",
    "\n",
    "    tag_id_groupby_gyro = sensor_data[(sensor_data.SENSORTYPE == 4)].groupby(['TagName', 'tester_id'])\n",
    "\n",
    "    tag_id_groupby_gravity = sensor_data[(sensor_data.SENSORTYPE == 9)].groupby(['TagName', 'tester_id'])\n",
    "\n",
    "    tag_id_linear_acc = sensor_data[(sensor_data.SENSORTYPE == 10)].groupby(['TagName', 'tester_id'])\n",
    "    \n",
    "    tag_id_groupby_quaternion = sensor_data[(sensor_data.SENSORTYPE == 11)].groupby(['TagName', 'tester_id'])\n",
    "\n",
    "    tag_id_groupby_tilt = sensor_data[(sensor_data.SENSORTYPE == 26)].groupby(['TagName', 'tester_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_frame_no = 1 \n",
    "\n",
    "test_percent = 0.1 # 10% samples are used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def shrink_array(array,size):\n",
    "    \n",
    "#     ratio = float(len(array)) / float(size)\n",
    "#     res = []\n",
    "#     for i in range(size):\n",
    "#         res.append(np.mean(array[math.floor(i*ratio):math.ceil((i+1.0)*ratio)], axis = 0))\n",
    "#     return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overlap\n",
    "def shrink_array(array,size):\n",
    "    \n",
    "    ratio = float(len(array)) / float(size+1)\n",
    "    res = []\n",
    "    for i in range(size):\n",
    "        res.append(np.mean(array[math.floor(i*ratio):math.ceil((i+2.0)*ratio)], axis = 0))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gesture_features(accs):\n",
    "#     for i in range(accs.shape[0]): # x, y, z\n",
    "#         accs[i] = min_max_normalization(accs[i], np.min(accs[i]), np.max(accs[i]))\n",
    "        \n",
    "    if N_frame_no > 1:\n",
    "        Ls = math.floor(len(accs)/ (N_frame_no + 1))\n",
    "        segments = None\n",
    "        for i in range(N_frame_no + 1):\n",
    "            if segments is None:\n",
    "                segments = np.array([accs[i*Ls:(i+1)*Ls]])\n",
    "            else:\n",
    "                segments = np.append(segments, np.array([accs[i*Ls:(i+1)*Ls]]), axis=0)\n",
    "\n",
    "        frames = None\n",
    "        for i in range(N_frame_no):\n",
    "            cur_frame = segments[i:i+2]\n",
    "            cur_frame = cur_frame.reshape((cur_frame.shape[0]*cur_frame.shape[1],cur_frame.shape[2]))\n",
    "            if frames is None:\n",
    "                frames = np.array([cur_frame])\n",
    "            else:\n",
    "                frames = np.append(frames, np.array([cur_frame]), axis = 0)\n",
    "        return np.array([frame_features(f) for f in frames]).reshape(-1)\n",
    "    else:\n",
    "        return frame_features(accs).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frame_features(cur_frame):\n",
    "    \n",
    "    mean_cur_frame = np.mean(cur_frame ,axis= 0)\n",
    "    \n",
    "    energy_cur_frame=[]\n",
    "    for T in range(cur_frame.shape[1]): #x,y,z\n",
    "        T_sum = 0\n",
    "        for i in cur_frame[:,T]:\n",
    "            T_sum += math.pow(abs(i),2)\n",
    "        energy_cur_frame.append(T_sum / len(cur_frame))\n",
    "    energy_cur_frame = np.array(energy_cur_frame)\n",
    "    \n",
    "    entropy_cur_frame = []\n",
    "    for T in range(cur_frame.shape[1]): #x,y,z\n",
    "        T_sum = 0\n",
    "        entropy_sum = 0\n",
    "        for i in cur_frame[:,T]:\n",
    "            T_sum += abs(i)\n",
    "            \n",
    "        for m in cur_frame[:,T]:\n",
    "            p_m_T = abs(m)/T_sum\n",
    "            entropy_sum += p_m_T*math.log(1/p_m_T)\n",
    "\n",
    "        entropy_cur_frame.append(entropy_sum)\n",
    "    entropy_cur_frame = np.array(entropy_cur_frame)\n",
    "    \n",
    "    std_cur_frame = np.std(cur_frame, axis=0)\n",
    "    \n",
    "    ## TODO     ## TODO    ## TODO    ## TODO    ## TODO    ## TODO    ## TODO    ## TODO\n",
    "    ## TODO     ## TODO    ## TODO    ## TODO    ## TODO    ## TODO    ## TODO    ## TODO\n",
    "    ## TODO     ## TODO    ## TODO    ## TODO    ## TODO    ## TODO    ## TODO    ## TODO\n",
    "    # correlation\n",
    "    \n",
    "    return np.concatenate((mean_cur_frame,energy_cur_frame,std_cur_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # X = []\n",
    "\n",
    "# # for key in list(tag_id_dict.keys()):\n",
    "# #     gesture_feature = gesture_features(tag_id_groupby.get_group(key)[['VALUES1', 'VALUES2', 'VALUES3']].values).reshape(-1)\n",
    "# #     if np.all(~np.isnan(gesture_feature)):\n",
    "# #         X.append(gesture_feature)\n",
    "# #     else:\n",
    "# #         print(key)\n",
    "# # X = np.array(X)\n",
    "\n",
    "# X = []\n",
    "\n",
    "# for key in list(tag_id_dict.keys()):\n",
    "\n",
    "#     acc_feature = shrink_array(tag_id_groupby_acc.get_group(key)[['VALUES1','VALUES2', 'VALUES3']].values, 30)\n",
    "# #     acc_feature = min_max_normalization(acc_feature)\n",
    "\n",
    "    \n",
    "# #     gyro_feature = shrink_array(tag_id_groupby_gyro.get_group(key)[['VALUES1','VALUES2', 'VALUES3']].values, 30)\n",
    "# #     orientation_feature = shrink_array(tag_id_groupby_orientation.get_group(key)[['VALUES1', 'VALUES2', 'VALUES3']].values, 30)\n",
    "# #     quaternion_feature = shrink_array(tag_id_groupby_quaternion.get_group(key)[['VALUES1','VALUES2', 'VALUES3']].values, 30)\n",
    "# #     magnetic_feature = shrink_array(tag_id_groupby_magnetic.get_group(key)[['VALUES1','VALUES2', 'VALUES3']].values, 30)\n",
    "# #     if key in tag_id_groupby_tilt.groups:\n",
    "# #         tilt_feature = np.array([1])\n",
    "# #     else:\n",
    "# #         tilt_feature = np.array([0])\n",
    "        \n",
    "#     X.append(acc_feature)\n",
    "# #     X.append(np.concatenate((acc_feature, tilt_feature)))\n",
    "    \n",
    "# X = np.array(X)\n",
    "# # pca = PCA(n_components=1)\n",
    "# # pca.fit(X.reshape(-1,3))\n",
    "# # X = pca.transform(X.reshape(-1,3))\n",
    "# # X = X.reshape(int(X.shape[0]/30), 30)\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for key in list(tag_id_linear_acc.groups.keys()):\n",
    "    linear_acc_feature = shrink_array(tag_id_linear_acc.get_group(key)[['VALUES1', 'VALUES2', 'VALUES3']].values, 30)\n",
    "#     acc_feature = shrink_array(tag_id_groupby_acc.get_group(key)[['VALUES1', 'VALUES2', 'VALUES3']].values, 30)\n",
    "    X.append(linear_acc_feature)\n",
    "#     X.append(np.concatenate((acc_feature, linear_acc_feature), axis = 1))\n",
    "    y.append(key[0])\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "linear_acc_feature_groups = linear_acc_feature.groupby(['TagName','tester_id'])\n",
    "for key in list(linear_acc_feature_groups.groups.keys()):\n",
    "    linear_acc_feature = shrink_array(linear_acc_feature_groups.get_group(key)[['linear_distance_x',\n",
    "                                                                                'linear_distance_y', \n",
    "                                                                                'linear_distance_z', \n",
    "                                                                                'linear_velocity_x',\n",
    "                                                                                'linear_velocity_y', \n",
    "                                                                                'linear_velocity_z']].values, 30)\n",
    "#     acc_feature = shrink_array(tag_id_groupby_acc.get_group(key)[['VALUES1', 'VALUES2', 'VALUES3']].values, 30)\n",
    "    X.append(linear_acc_feature)\n",
    "#     X.append(np.concatenate((acc_feature, linear_acc_feature), axis = 1))\n",
    "    y.append(key[0])\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 30, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_list = list(range(len(X)))\n",
    "np.random.shuffle(idx_list)\n",
    "train_idx = idx_list[:math.floor(len(X) * (1- test_percent))]\n",
    "test_idx = idx_list[math.floor(len(X) * (1- test_percent)):]\n",
    "\n",
    "# y[y == 'Tag2'] = 2\n",
    "# y[y == 'Tag1'] = 1\n",
    "\n",
    "train_x = X[train_idx]\n",
    "train_y = y[train_idx]\n",
    "test_x = X[test_idx]\n",
    "test_y = y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda = LinearDiscriminantAnalysis()\n",
    "# lda.fit(train_x.reshape(train_x.shape[0],90),train_y)\n",
    "# train_x = lda.transform(train_x.reshape(train_x.shape[0],90))\n",
    "# test_x = lda.transform(test_x.reshape(test_x.shape[0],90))\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][ 0.58571429  0.6         0.4952381   0.6         0.445     ]\n",
      "0.54519047619\n"
     ]
    }
   ],
   "source": [
    "clf4 = SVC(kernel='poly', C=1, degree=3, verbose = True)\n",
    "# clf4.fit(train_x, train_y) \n",
    "# joblib.dump(clf4, '../../Results/baseline SVC 0.80 raw data acc with gyro 200 chunk.pkl') \n",
    "# print(classification_report(test_y, clf4.predict(test_x)))\n",
    "if len(X.shape) > 2:\n",
    "    res = cross_val_score(clf4, X.reshape(list(X.shape)[0],-1), y, cv = 5)\n",
    "else:\n",
    "    res = cross_val_score(clf4, X, y, cv=5)\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(train_x, train_y)\n",
    "print(classification_report(test_y, clf.predict(test_x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'             precision    recall  f1-score   support\\n\\n       Tag0       0.25      0.42      0.31        12\\n       Tag1       0.50      1.00      0.67        11\\n       Tag2       0.56      0.83      0.67         6\\n       Tag3       0.60      0.75      0.67        12\\n       Tag4       0.60      0.60      0.60         5\\n       Tag5       0.80      0.44      0.57         9\\n       Tag6       0.25      0.06      0.10        16\\n       Tag7       0.17      0.20      0.18         5\\n       Tag8       0.78      0.41      0.54        17\\n       Tag9       0.67      0.55      0.60        11\\n\\navg / total       0.53      0.50      0.48       104\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.fit(train_x.reshape(len(train_x),-1), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Tag0       0.25      0.42      0.31        12\n",
      "       Tag1       0.50      1.00      0.67        11\n",
      "       Tag2       0.56      0.83      0.67         6\n",
      "       Tag3       0.60      0.75      0.67        12\n",
      "       Tag4       0.60      0.60      0.60         5\n",
      "       Tag5       0.80      0.44      0.57         9\n",
      "       Tag6       0.25      0.06      0.10        16\n",
      "       Tag7       0.17      0.20      0.18         5\n",
      "       Tag8       0.78      0.41      0.54        17\n",
      "       Tag9       0.67      0.55      0.60        11\n",
      "\n",
      "avg / total       0.53      0.50      0.48       104\n",
      "\n",
      "[[ 5  2  0  3  0  0  0  1  1  0]\n",
      " [ 0 11  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  5  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  9  1  0  0  0  0  0]\n",
      " [ 1  1  0  0  3  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  4  1  1  1  0]\n",
      " [12  2  0  0  0  0  1  1  0  0]\n",
      " [ 0  2  0  1  0  0  0  1  0  1]\n",
      " [ 2  1  1  1  0  1  2  0  7  2]\n",
      " [ 0  0  1  1  1  0  0  2  0  6]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, clf4.predict(test_x.reshape(len(test_x),-1))))\n",
    "print(confusion_matrix(test_y, clf4.predict(test_x.reshape(len(test_x),-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
