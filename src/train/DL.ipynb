{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963, 9, 4, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "import keras\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "sensor_data = pd.DataFrame.from_csv(\"../../data/database/sensor_data.csv\")\n",
    "Counter(sensor_data.TagName)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "sensor_data_acc = sensor_data[sensor_data.SENSORTYPE == 1]\n",
    "sensor_data_acc_number_tag = sensor_data_acc[~((sensor_data_acc.TagName == 'Tag0') | (sensor_data_acc.TagName == 'Start1') | (sensor_data_acc.TagName == 'Start2'))]\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "Counter(sensor_data_acc_number_tag.TagName)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "# tag_id_groupby = sensor_data_acc_tag12.groupby(['TagName', 'tester_id'])\n",
    "tag_id_groupby = sensor_data_acc_number_tag.groupby(['TagName', 'tester_id'])\n",
    "tag_id_dict = tag_id_groupby.groups\n",
    "y = list(tag_id_dict.keys())\n",
    "y = [i[0] for i in y]\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "y.shape\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "# there will be 9 frames, frame0 to frame8\n",
    "# There will be 10 segments\n",
    "N_frame_no = 9 \n",
    "\n",
    "test_percent = 0.1 # 10% samples are used for testing\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "def gesture_features(accs):\n",
    "    Ls = math.floor(len(accs)/ (N_frame_no + 1))\n",
    "    segments = None\n",
    "    for i in range(N_frame_no + 1):\n",
    "        if segments is None:\n",
    "            segments = np.array([accs[i*Ls:(i+1)*Ls]])\n",
    "        else:\n",
    "            segments = np.append(segments, np.array([accs[i*Ls:(i+1)*Ls]]), axis=0)\n",
    "\n",
    "    frames = None\n",
    "    for i in range(N_frame_no):\n",
    "        cur_frame = segments[i:i+2]\n",
    "        cur_frame = cur_frame.reshape((cur_frame.shape[0]*cur_frame.shape[1],cur_frame.shape[2]))\n",
    "        if frames is None:\n",
    "            frames = np.array([cur_frame])\n",
    "        else:\n",
    "            frames = np.append(frames, np.array([cur_frame]), axis = 0)\n",
    "    return np.array([frame_features(f,Ls) for f in frames])\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "def frame_features(cur_frame, Ls):\n",
    "    dft_cur_frame = np.fft.fftn(cur_frame)\n",
    "    \n",
    "    mean_cur_frame = np.array([dft_cur_frame[0]])\n",
    "\n",
    "    energy_cur_frame=[]\n",
    "    for T in range(cur_frame.shape[1]): #x,y,z\n",
    "        T_sum = 0\n",
    "        for i in range(1,Ls*2):\n",
    "            T_sum += math.pow(abs(dft_cur_frame[i,T]),2)\n",
    "\n",
    "        energy_cur_frame.append(T_sum / abs(Ls*2-1))\n",
    "    energy_cur_frame = np.array([energy_cur_frame])\n",
    "    \n",
    "    entropy_cur_frame = []\n",
    "    for T in range(cur_frame.shape[1]): #x,y,z\n",
    "        T_sum = 0\n",
    "        entropy_sum = 0\n",
    "        for i in range(1,Ls*2):\n",
    "            T_sum += abs(dft_cur_frame[i,T])\n",
    "\n",
    "        for m in range(1,Ls*2):\n",
    "            p_m_T = abs(dft_cur_frame[m,T])/T_sum\n",
    "            entropy_sum += p_m_T*math.log(1/p_m_T)\n",
    "        entropy_cur_frame.append(entropy_sum)\n",
    "    entropy_cur_frame = np.array([entropy_cur_frame])\n",
    "    \n",
    "    std_cur_frame = []\n",
    "    for T in range(cur_frame.shape[1]): #x,y,z\n",
    "        std_cur_frame.append(np.std(cur_frame))\n",
    "    std_cur_frame = np.array([std_cur_frame])\n",
    "    \n",
    "    ## TODO     ## TODO    ## TODO    ## TODO    ## TODO    ## TODO    ## TODO    ## TODO\n",
    "    ## TODO     ## TODO    ## TODO    ## TODO    ## TODO    ## TODO    ## TODO    ## TODO\n",
    "    ## TODO     ## TODO    ## TODO    ## TODO    ## TODO    ## TODO    ## TODO    ## TODO\n",
    "    # correlation\n",
    "    \n",
    "    return np.concatenate((mean_cur_frame,energy_cur_frame,std_cur_frame,entropy_cur_frame))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "X = []\n",
    "for key in list(tag_id_dict.keys()):\n",
    "    X.append(gesture_features(tag_id_groupby.get_group(key)[['VALUES1', 'VALUES2', 'VALUES3']].values))\n",
    "X = np.array(X)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_y = np.zeros(y.shape)\n",
    "for num, tag_str in list(enumerate(set(y))):\n",
    "    cloned_y[y==tag_str] = num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_categorical = keras.utils.to_categorical(cloned_y, num_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_feature(feature):\n",
    "    maxi = max(feature.reshape(-1))\n",
    "    mini = min(feature.reshape(-1))\n",
    "    return (feature - mini) / (maxi - mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape (..., 9, 4, 3)\n",
    "normalized_X = None\n",
    "for feature_idx in range(X.shape[2]):\n",
    "    cur_normed = normalize_feature(X[:,:,feature_idx,:]).reshape((len(X), X.shape[1]*X.shape[3]))\n",
    "    if normalized_X is None:\n",
    "        normalized_X = cur_normed\n",
    "    else:\n",
    "        normalized_X = np.append(normalized_X, cur_normed, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963, 108)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/numpy/core/numeric.py:531: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.25      0.11      0.15         9\n",
      "        1.0       0.50      0.22      0.31         9\n",
      "        2.0       0.15      0.88      0.25         8\n",
      "        3.0       1.00      0.36      0.53        14\n",
      "        4.0       0.75      0.38      0.50         8\n",
      "        5.0       0.00      0.00      0.00        10\n",
      "        6.0       0.00      0.00      0.00        18\n",
      "        7.0       0.33      0.92      0.49        12\n",
      "        8.0       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.33      0.30      0.24        97\n",
      "\n",
      "[[ 1  0  2  0  0  0  0  6  0]\n",
      " [ 0  2  5  0  0  0  0  2  0]\n",
      " [ 0  0  7  0  0  0  0  1  0]\n",
      " [ 0  0  5  5  0  0  0  4  0]\n",
      " [ 0  0  1  0  3  0  0  4  0]\n",
      " [ 0  0 10  0  0  0  0  0  0]\n",
      " [ 0  1 17  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 11  0]\n",
      " [ 3  1  0  0  0  0  0  5  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ageha/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "idx_list = list(range(y.size))\n",
    "np.random.shuffle(idx_list)\n",
    "train_idx = idx_list[:math.floor(len(X) * (1- test_percent))]\n",
    "test_idx = idx_list[math.floor(len(X) * (1- test_percent)):]\n",
    "\n",
    "\n",
    "train_x = normalized_X[train_idx]\n",
    "train_y = y_categorical[train_idx]\n",
    "test_x = normalized_X[test_idx]\n",
    "test_y = y_categorical[test_idx]\n",
    "\n",
    "\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(normalized_X.shape[1],))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "layer1 = Dense(64, activation='relu')(inputs)\n",
    "layer2 = Dense(128, activation='relu')(layer1)\n",
    "layer3 = Dense(64, activation='relu')(layer2)\n",
    "layer4 = Dense(32, activation='relu')(layer3)\n",
    "predictions = Dense(y_categorical.shape[-1], activation='softmax')(layer4)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_his = model.fit(train_x, train_y, batch_size=32, epochs=40, verbose = 0)  # starts training\n",
    "pred_y = model.predict(test_x)\n",
    "result_label = np.argmax(pred_y, 1)\n",
    "print(classification_report(cloned_y[test_idx],result_label))\n",
    "print(confusion_matrix(cloned_y[test_idx],result_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
