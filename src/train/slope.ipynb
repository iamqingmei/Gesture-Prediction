{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import linregress\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Tag0': 352461,\n",
       "         'Tag1': 272234,\n",
       "         'Tag2': 377420,\n",
       "         'Tag3': 398370,\n",
       "         'Tag4': 428642,\n",
       "         'Tag5': 435086,\n",
       "         'Tag6': 358288,\n",
       "         'Tag7': 315266,\n",
       "         'Tag8': 431390,\n",
       "         'Tag9': 381880})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_data = pd.DataFrame.from_csv(\"../../data/database/sensor_data.csv\")\n",
    "sensor_data = sensor_data[~((sensor_data.TagName == 'Start1') | (sensor_data.TagName == 'Start2'))]\n",
    "Counter(sensor_data.TagName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def min_max_normalization(feature, mini, maxi):\n",
    "    if (maxi == mini):\n",
    "        # all the values is same:\n",
    "        return np.array([1] * len(feature))\n",
    "    if type(feature) == list:\n",
    "        feature = np.array(feature)\n",
    "    feature[feature < mini] = mini\n",
    "    feature[feature > maxi] = maxi\n",
    "\n",
    "    feature = ((feature - mini) / (maxi - mini))\n",
    "    return feature\n",
    "\n",
    "if os.path.exists(\"../../Results/percentiles.txt\") is False:\n",
    "    \n",
    "    percentile_df = pd.DataFrame.from_csv(\"../../Results/percentiles.txt\")\n",
    "\n",
    "    normalized_sensor_data = sensor_data.copy()\n",
    "    for i in range(len(percentile_df)):\n",
    "        cur = percentile_df.iloc[i].values\n",
    "        sensor = cur[0]\n",
    "        val = cur[1]\n",
    "        p97 = cur[2]\n",
    "        p03 = cur[3]\n",
    "        normalized_sensor_data.loc[(sensor_data.SENSORTYPE == sensor),val] = min_max_normalization(sensor_data[(sensor_data.SENSORTYPE == sensor)][val].values, p03, p97)\n",
    "\n",
    "    normalized_sensor_data.to_csv(\"../../data/database/normalized_sensor_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sensor_data_acc = sensor_data[(sensor_data.SENSORTYPE == 1)]\n",
    "# tag_id_groupby = sensor_data_acc_tag12.groupby(['TagName', 'tester_id'])\n",
    "tag_id_groupby_acc = sensor_data_acc.groupby(['TagName', 'tester_id'])\n",
    "tag_id_dict = tag_id_groupby_acc.groups\n",
    "y = list(tag_id_dict.keys())\n",
    "y = [i[0] for i in y]\n",
    "y = np.array(y)\n",
    "\n",
    "sensor_data_magnetic = sensor_data[(sensor_data.SENSORTYPE == 2)]\n",
    "tag_id_groupby_magnetic = sensor_data_magnetic.groupby(['TagName', 'tester_id'])\n",
    "\n",
    "sensor_data_orientation = sensor_data[(sensor_data.SENSORTYPE == 3)]\n",
    "tag_id_groupby_orientation = sensor_data_orientation.groupby(['TagName', 'tester_id'])\n",
    "\n",
    "sensor_data_gyro = sensor_data[(sensor_data.SENSORTYPE == 4)]\n",
    "tag_id_groupby_gyro = sensor_data_gyro.groupby(['TagName', 'tester_id'])\n",
    "\n",
    "sensor_data_gravity = sensor_data[(sensor_data.SENSORTYPE == 9)]\n",
    "tag_id_groupby_gravity = sensor_data_gravity.groupby(['TagName', 'tester_id'])\n",
    "\n",
    "sensor_data_quaternion = sensor_data[(sensor_data.SENSORTYPE == 11)]\n",
    "tag_id_groupby_quaternion = sensor_data_quaternion.groupby(['TagName', 'tester_id'])\n",
    "\n",
    "sensor_data_tilt = sensor_data[(sensor_data.SENSORTYPE == 26)]\n",
    "tag_id_groupby_tilt = sensor_data_tilt.groupby(['TagName', 'tester_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_slope(x, y, size):\n",
    "    ratio = float(len(x)) / float(size)\n",
    "    res1 = []\n",
    "    res2 = []\n",
    "    for i in range(size):\n",
    "        res2.append(list(y[math.floor(i*ratio):math.ceil((i+1.0)*ratio)]))\n",
    "        res1.append(list(x[math.floor(i*ratio):math.ceil((i+1.0)*ratio)]))\n",
    "    slopes = []\n",
    "    for i in range(len(res1)):\n",
    "        if (len(set(list(res1[i]))) == 1):\n",
    "            slopes.append(0)\n",
    "        else:\n",
    "            slopes.append(linregress(res1[i], res2[i]).slope)\n",
    "    return np.array(slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shrink_array(array,size):\n",
    "    \n",
    "    ratio = float(len(array)) / float(size)\n",
    "    res = []\n",
    "    for i in range(size):\n",
    "        res.append(np.mean(array[math.floor(i*ratio):math.ceil((i+1.0)*ratio)], axis = 0))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = []\n",
    "\n",
    "# for key in list(tag_id_dict.keys()):\n",
    "#     gesture_feature = gesture_features(tag_id_groupby.get_group(key)[['VALUES1', 'VALUES2', 'VALUES3']].values).reshape(-1)\n",
    "#     if np.all(~np.isnan(gesture_feature)):\n",
    "#         X.append(gesture_feature)\n",
    "#     else:\n",
    "#         print(key)\n",
    "# X = np.array(X)\n",
    "\n",
    "X = []\n",
    "\n",
    "for key in list(tag_id_dict.keys()):\n",
    "#     t = pd.to_datetime(tag_id_groupby_acc.get_group(key)['TIMESTAMP']).values.astype(datetime.datetime)/100000\n",
    "#     acc_1_slope = get_slope(tag_id_groupby_acc.get_group(key)['VALUES1'].values, t , 200)\n",
    "#     acc_2_slope = get_slope(tag_id_groupby_acc.get_group(key)['VALUES2'].values, t , 200)\n",
    "#     acc_3_slope = get_slope(tag_id_groupby_acc.get_group(key)['VALUES3'].values, t , 200)\n",
    "    \n",
    "#     acc_12_slope_dif = acc_1_slope - acc_2_slope\n",
    "#     acc_23_slope_dif = acc_2_slope - acc_3_slope\n",
    "#     acc_13_slope_dif = acc_1_slope - acc_3_slope\n",
    "    \n",
    "    acc_12_slope = get_slope(tag_id_groupby_acc.get_group(key)['VALUES1'].values, tag_id_groupby_acc.get_group(key)['VALUES2'].values , 200)\n",
    "    acc_23_slope = get_slope(tag_id_groupby_acc.get_group(key)['VALUES2'].values, tag_id_groupby_acc.get_group(key)['VALUES3'].values , 200)\n",
    "    acc_13_slope = get_slope(tag_id_groupby_acc.get_group(key)['VALUES3'].values, tag_id_groupby_acc.get_group(key)['VALUES3'].values , 200)\n",
    "    acc_feature = shrink_array(tag_id_groupby_acc.get_group(key)[['VALUES1','VALUES2', 'VALUES3']].values, 200).reshape(-1)\n",
    "    \n",
    "    \n",
    "#     gyro_feature = shrink_array(tag_id_groupby_gyro.get_group(key)[['VALUES1','VALUES2', 'VALUES3']].values, 200).reshape(-1)\n",
    "#     orientation_feature = shrink_array(tag_id_groupby_orientation.get_group(key)[['VALUES1', 'VALUES2', 'VALUES3']].values, 200).reshape(-1)\n",
    "\n",
    "#     quaternion_feature = shrink_array(tag_id_groupby_quaternion.get_group(key)[['VALUES1','VALUES2', 'VALUES3']].values, 200).reshape(-1)\n",
    "#     magnetic_feature = shrink_array(tag_id_groupby_magnetic.get_group(key)[['VALUES1','VALUES2', 'VALUES3']].values, 200).reshape(-1)\n",
    "\n",
    "#     if key in tag_id_groupby_tilt.groups:\n",
    "#         tilt_feature = np.array([1])\n",
    "#     else:\n",
    "#         tilt_feature = np.array([0])\n",
    "\n",
    "#     X.append(acc_feature)\n",
    "\n",
    "    X.append(np.concatenate((acc_feature, acc_12_slope, acc_23_slope, acc_13_slope)))\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 1200)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][ 0.78181818  0.85        0.68571429  0.84761905  0.68571429]\n",
      "0.770173160173\n"
     ]
    }
   ],
   "source": [
    "# idx_list = list(range(len(X)))\n",
    "# np.random.shuffle(idx_list)\n",
    "# train_idx = idx_list[:math.floor(len(X) * (1- test_percent))]\n",
    "# test_idx = idx_list[math.floor(len(X) * (1- test_percent)):]\n",
    "\n",
    "# # y[y == 'Tag2'] = 2\n",
    "# # y[y == 'Tag1'] = 1\n",
    "\n",
    "# train_x = X[train_idx]\n",
    "# train_y = y[train_idx]\n",
    "# test_x = X[test_idx]\n",
    "# test_y = y[test_idx]\n",
    "\n",
    "clf4 = SVC(kernel='poly', C=1, degree=3, verbose = True)\n",
    "# clf4.fit(train_x, train_y) \n",
    "# joblib.dump(clf4, '../../Results/baseline SVC 0.80 raw data acc with gyro 200 chunk.pkl') \n",
    "# print(classification_report(test_y, clf4.predict(test_x)))\n",
    "res = cross_val_score(clf4, X, y, cv=5)\n",
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
